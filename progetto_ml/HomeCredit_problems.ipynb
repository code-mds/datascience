{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan repay prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data location: https://drive.switch.ch/index.php/s/pCy5ctcFRsM2RdZ\n",
    "\n",
    "Consider file `HomeCredit_train.csv`, which contains anonymized data shared from a financial institution (https://www.kaggle.com/c/home-credit-default-risk/).\n",
    "\n",
    "Each row is a loan.  See `HomeCredit_description.csv` for a description of the columns (note that we only have a subset of the columns).  The target variable (column `TARGET`) contains 1 if the client had issues repaying the loan, 0 otherwise.\n",
    "\n",
    "If you need it for faster experiments, the file  `HomeCredit_train_small.csv` contains only a small part of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: exploratory analysis\n",
    "Open the dataset using Pandas.\n",
    "\n",
    "### 1.1\n",
    "Which fraction of the loans are not repayed? \n",
    "\n",
    "### 1.2\n",
    "Choose 3 variables you like and whose meaning you understand. Make one or two plots for each to describe its distribution (univariate analysis), and to check whether there is an obvious relation to the target variable (bivariate analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 \n",
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv(\"HomeCredit_train_small.csv\")\n",
    "df = pd.read_csv(\"HomeCredit_train.csv\")\n",
    "df_blind = pd.read_csv(\"HomeCredit_test_blind.csv\")\n",
    "m = df[\"TARGET\"].mean()\n",
    "print(f\"Fraction of not repayed loans = {m:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "df_unpaid = df[df['TARGET']==1]\n",
    "df_paid = df[df['TARGET']==0]\n",
    "\n",
    "def unpaid_comparison(df, df_unpaid, col, title):\n",
    "    ## Counts the occurrence of unqiue elements and stores in a series type\n",
    "    data = df[col].value_counts()\n",
    "    data.sort_values(ascending=False, inplace=True)\n",
    "    #top 10\n",
    "    data = data.head(10)\n",
    "    \n",
    "    f2 = go.Bar(x=data.values/np.sum(data)*100, y=data.index, orientation='h',\n",
    "                marker_color='rgba(0, 0, 255, 0.7)')\n",
    "\n",
    "    data_unpaid = df_unpaid[col].value_counts() / data * 100.0\n",
    "    data_unpaid.sort_values(ascending=False, inplace=True)\n",
    "    #top 10\n",
    "    data_unpaid = data_unpaid.head(10)\n",
    "    \n",
    "    f1 = go.Bar(x=data_unpaid.values, y=data_unpaid.index, orientation='h', \n",
    "                marker_color='rgba(255, 0, 0, 0.7)')\n",
    "    \n",
    "    fig = make_subplots(shared_xaxes=False, rows=2, cols=1) #, vertical_spacing=0.25)\n",
    "    fig.add_trace(f2, row=2, col=1)\n",
    "    fig.add_trace(f1, row=1, col=1)\n",
    "    fig.update_yaxes(row=2, col=1, autorange=\"reversed\")\n",
    "    fig.update_xaxes(title_text=\"% of people obtained a credit\", row=2, col=1)\n",
    "    fig.update_yaxes(row=1, col=1, autorange=\"reversed\")\n",
    "    fig.update_xaxes(title_text=\"% of not paid loan\", row=1, col=1)\n",
    "    fig.update_layout(title_text=title)\n",
    "    fig.update_traces(showlegend=False)\n",
    "    fig.show()\n",
    "    \n",
    "#F    9247/131546\n",
    "#M    6962/68452\n",
    "#XNA  0/2\n",
    "#dfp = df_unpaid['CODE_GENDER'].value_counts() / df['CODE_GENDER'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = unpaid_comparison(df, df_unpaid, 'CODE_GENDER', 'Unpaid Loan By Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'OCCUPATION_TYPE', 'Top 10 Unpaid Loan By Occupation Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'NAME_HOUSING_TYPE', 'Unpaid Loan By Housing Situation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'NAME_EDUCATION_TYPE', 'Unpaid Loan By Education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'ORGANIZATION_TYPE', 'Top 10 Unpaid Loan By Type of organization where client works')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: preparing a training and a validation dataset\n",
    "\n",
    "### 2.1\n",
    "Randomly split the 200k rows of your dataset in two groups; keep 150k rows for training and use 50k for validating your models.\n",
    "\n",
    "### 2.2\n",
    "Choose three variables that are already numeric.  Build the following numpy arrays:\n",
    "- `X_tr` (2 dimensions: 150k rows, 3 columns)\n",
    "- `y_tr` (1 dimension: 150k elements)\n",
    "- `X_val` (2 dimensions: 50k rows, 3 columns)\n",
    "- `y_val` (1 dimension: 50k elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "msk = np.random.rand(len(df)) < 3/4\n",
    "train = df[msk] # 150'000 rows\n",
    "test = df[~msk] # 50'000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 - numeric variables\n",
    "cols = ['AMT_INCOME_TOTAL','AMT_CREDIT', 'REGION_POPULATION_RELATIVE']\n",
    "\n",
    "X_tr = train[cols]\n",
    "y_tr = train['TARGET']\n",
    "\n",
    "X_val = test[cols]\n",
    "y_val = test['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: training and scoring simple models\n",
    "\n",
    "### 3.1\n",
    "Train a K-Nearest-Neighbors classifier (use the sklearn function) and compute its accuracy on the validation set.  Compare it with the accuracy of a classifier that always returns 0.  Comment.\n",
    "\n",
    "### 3.2\n",
    "Train the classifier with K=20, and use the `predict_proba(...)` function on the trained classifier to obtain a *score* for each instance in the validation set.  Consider the distribution of the scores returned for the instances of the validation set.\n",
    "\n",
    "Describe what is in this context the concept of TP, TN, FP, FN, TPR, FPR.\n",
    "\n",
    "Write a function that given a threshold, computes the number of TP, TN, FP, FN. \n",
    "\n",
    "How would you describe what the TPR and FPR are in this context?\n",
    "\n",
    "\n",
    "### 3.3\n",
    "Using your function defined above, compute the TPR and FPR for a large number of different thresholds.  Plot the ROC curve.\n",
    "\n",
    "Using the [appropriate sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), compute the AUC of your classifier.\n",
    "\n",
    "### 3.4\n",
    "Draw the ROC curve and compute the AUC value for two \"dummy\" classifiers:\n",
    "- one that always returns a score of 0 for each sample\n",
    "- one that returns a random score for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "clf_kn2 = sklearn.neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "clf_kn2.fit(X_tr, y_tr)\n",
    "\n",
    "y_hat = clf_kn2.predict(X_val)\n",
    "accurancy_kn = np.mean(y_hat == y_val)\n",
    "\n",
    "y_hat_dummy = [0] * len(y_val)\n",
    "accurancy_dummy = np.mean(y_hat_dummy == y_val)\n",
    "print(f'Accurancy KN(2)\\t {accurancy_kn:.4f}')\n",
    "print(f'Accurancy Dummy\\t {accurancy_dummy:.4f}')\n",
    "print(f'Difference\\t{accurancy_kn-accurancy_dummy:.4f}')\n",
    "print(f'With this configuration the Dummy Classifier works better than a KNeighbour(2).')\n",
    "print(f'It can be explained by the fact that the % of positive cases are very low in the context of this problem.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 - Train the classifier with KNeighborsClassifier using n_neighbors=20\n",
    "\n",
    "clf_kn20 = sklearn.neighbors.KNeighborsClassifier(n_neighbors=20)\n",
    "clf_kn20.fit(X_tr, y_tr)\n",
    "y_score_kn20 = clf_kn20.predict_proba(X_val)[:,1]\n",
    "y_hat = y_score_kn20 > 0.5\n",
    "accurancy_kn_20 = np.mean(y_hat == y_val)\n",
    "\n",
    "def roc_calculator(t, y_val, y_sc):\n",
    "    matrix = sklearn.metrics.confusion_matrix(y_val, y_sc > t)\n",
    "    TN=matrix[0][0]\n",
    "    FP=matrix[0][1]\n",
    "    FN=matrix[1][0]\n",
    "    TP=matrix[1][1]\n",
    "    # FNR = False Negative Rate \n",
    "    FNR=FN/(FN+TP)    \n",
    "    # FPR = False Positive Rate \n",
    "    FPR=FP/(TN+FP)\n",
    "    # TPR = True Positive Rate\n",
    "    TPR=1-FNR \n",
    "    return TPR, FPR\n",
    "\n",
    "# Description in the context of the problem\n",
    "# [TN, FP] -> TN+FP = Totale Paganti\n",
    "# [FN, TP] -> FN+TP = Totale Insolventi\n",
    "# TP = Correctly prediceted as: non-paganti.\n",
    "# TN = Correctly prediceted as: paganti.\n",
    "# FP = Wrongly prediceted as: non-paganti.\n",
    "# FN = Wrongly prediceted as: paganti.\n",
    "# TPR = % of correctly predicted as: non paganti.\n",
    "# FPR = % of wrongly predicted as: non paganti.\n",
    "\n",
    "# distribution of y scores\n",
    "fig = go.Figure(go.Histogram(x=y_score_kn20))\n",
    "fig.update_layout(\n",
    "    title='Distribution of scores for a KNeighbour(20) Classifier',\n",
    "    xaxis=dict(title='y scores'),\n",
    "    yaxis=dict(title='Count'),  \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.3\n",
    "def print_roc_curve(y_val, y_sc, name):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    # Calculate the AUC (Area Under Curve)\n",
    "    AUC = sklearn.metrics.roc_auc_score(y_val, y_sc)\n",
    "    \n",
    "    for i in  np.arange(0, 1, 0.02):\n",
    "        TPR,FPR = roc_calculator(i, y_val, y_sc)\n",
    "        x_values.append(FPR)\n",
    "        y_values.append(TPR)\n",
    "        \n",
    "    hat = y_sc > 0.5\n",
    "    acc = np.mean(hat == y_val)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=x_values, y=y_values, mode='lines+markers', name=name))\n",
    "    fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='baseline', line=dict(width=2, dash='dash')))\n",
    "    fig.update_layout(title=f'ROC curve for {name}<br>AUC={AUC:.3f} Accurancy={acc:.3f}', xaxis_title='%FP', yaxis_title='%TP', legend=dict(x=-.04, y=-.22))\n",
    "    fig.show()\n",
    "    return AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn20_auc = print_roc_curve(y_val, y_score_kn20, 'KNeighbors(20) Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.4\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "random_classifier.fit(X_tr, y_tr)\n",
    "y_score_random = random_classifier.predict_proba(X_val)[:,1]\n",
    "print_roc_curve(y_val, y_score_random, \"Random Classifier\")\n",
    "\n",
    "zero_classifier = DummyClassifier(strategy=\"constant\", constant=0)\n",
    "zero_classifier.fit(X_tr, y_tr)\n",
    "y_score_zero = zero_classifier.predict_proba(X_val)[:,1]\n",
    "print_roc_curve(y_val, y_score_zero, \"AlwaysZero Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: training better models (optional)\n",
    "\n",
    "### 4.1\n",
    "Normalize the data and repeat the analysis. Is the accuracy better?\n",
    "\n",
    "### 4.2\n",
    "Try using other classifiers.  A good option is the [random forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "### 4.3\n",
    "Try using more numerical features.\n",
    "\n",
    "### 4.4\n",
    "There is a lot of information also in the categorical features. Find a way to use them in a classifier.  For example, you can use One Hot Encoding, implementing it manually or by using the [appropriate sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
    "\n",
    "### 4.5\n",
    "Given a classifier, study how the AUC on the validation data decreases if you use only part of the training data.  Make a plot with the AUC on the y and the fraction of training data on the x. Compare for example 0.1%, 1%, 10%, 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1\n",
    "cols = ['AMT_INCOME_TOTAL','AMT_CREDIT', 'REGION_POPULATION_RELATIVE']\n",
    "\n",
    "def normalize(df, cols):\n",
    "    arr = np.array(df[cols])\n",
    "    X_tr_means = np.mean(arr, axis=0, keepdims=True)\n",
    "    X_tr_stds = np.std(arr, axis=0, keepdims=True)\n",
    "    X_tr_norm = (arr - X_tr_means) / X_tr_stds\n",
    "    return X_tr_norm\n",
    "\n",
    "X_tr_norm = normalize(X_tr, cols)\n",
    "X_te_norm = normalize(X_val, cols)\n",
    "\n",
    "clf_kn20_norm = sklearn.neighbors.KNeighborsClassifier(n_neighbors=20)\n",
    "clf_kn20_norm.fit(X_tr_norm, y_tr)\n",
    "y_score_norm = clf_kn20_norm.predict_proba(X_te_norm)[:,1]\n",
    "\n",
    "kn20_norm_auc = print_roc_curve(y_val, y_score_norm, 'KNeighbors(20) Classifier with Normalized values')\n",
    "\n",
    "accurancy_kn_20_norm = np.mean(clf_kn20_norm.predict(X_te_norm) == y_val)\n",
    "\n",
    "print(f'Not Normalized AUC={kn20_auc:.4f} Accurancy={accurancy_kn_20:.4f}')\n",
    "print(f'Normalized AUC={kn20_norm_auc:.4f} Accurancy={accurancy_kn_20_norm:.4f}')\n",
    "print('In this case, the AUC decreases while the Accurancy increases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2\n",
    "rf_classifier = RandomForestClassifier(max_depth=6, random_state=0)\n",
    "rf_classifier.fit(X_tr_norm, y_tr)\n",
    "y_score_randomforest = rf_classifier.predict_proba(X_te_norm)[:,1]\n",
    "random_forest_auc = print_roc_curve(y_val, y_score_randomforest, \"random forest classifier with normalized data\")\n",
    "accurancy_rf_norm = np.mean(rf_classifier.predict(X_te_norm) == y_val)\n",
    "print(f'Normalized AUC={random_forest_auc:.4f} Accurancy={accurancy_rf_norm:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_score(clf, x_tr, x_te):\n",
    "    clf.fit(x_tr, y_tr)\n",
    "    score = clf.predict_proba(x_te)[:,1]\n",
    "    auc = sklearn.metrics.roc_auc_score(y_val, score)\n",
    "    return auc,score\n",
    "def rf_auc(depth, x_tr, x_te):\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=0)\n",
    "    return auc_score(clf, x_tr, x_te)\n",
    "def kn_auc(k, x_tr, x_te):\n",
    "    clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    return auc_score(clf, x_tr, x_te)\n",
    "    \n",
    "def calc_max_auc(f_auc, start, end, x_tr, x_te):\n",
    "    aucs=[]\n",
    "    accs=[]\n",
    "    for d in range(start, end):\n",
    "        auc, sc = f_auc(d, x_tr, x_te)\n",
    "        acc = np.mean((sc > 0.5) == y_val)\n",
    "        aucs.append(auc)\n",
    "        accs.append(acc)\n",
    "        print(f'{d} -> AUC:{auc:.4f} ACC:{acc:.4f}')\n",
    "    max_auc = max(aucs)\n",
    "    idx = aucs.index(max_auc)\n",
    "    print(f'Max AUC:{max_auc:.4f} param: {idx+start} -> ACC: {accs[idx]:.4f}')\n",
    "    max_accurr = max(accs)\n",
    "    idx = accs.index(max_accurr)\n",
    "    print(f'Max ACC:{max_accurr:.4f} param: {idx+start} -> AUC: {aucs[idx]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# uncomment line below to test some parameters. It may take some time to run!!!\n",
    "print('Max AUC and Accurancy for KNeighbour changing the n_neighbors param')\n",
    "#calc_max_auc(kn_auc, 40, 50, X_tr_norm, X_te_norm)\n",
    "#47 -> AUC:0.5479 ACC:0.9194\n",
    "        \n",
    "print('Max AUC and Accurancy for Random Forest changing the max_depth param')\n",
    "#calc_max_auc(rf_auc, 1, 10, X_tr_norm, X_te_norm)\n",
    "#6 -> AUC:0.5596 ACC:0.9182\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 - Try using more numerical features.\n",
    "\n",
    "num_cols = cols + ['AMT_ANNUITY','CNT_CHILDREN','AMT_GOODS_PRICE', 'DAYS_EMPLOYED']\n",
    "for c in num_cols:\n",
    "    train[c].fillna(train[c].mean(), inplace=True)\n",
    "    test[c].fillna(test[c].mean(), inplace=True)\n",
    "    \n",
    "X_tr_num = normalize(train, num_cols)\n",
    "X_te_num = normalize(test, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max AUC and Accurancy for KNeighbour changing the n_neighbors param')\n",
    "#calc_max_auc(kn_auc, 1, 50, X_tr_num, X_te_num)\n",
    "# k:48 -> AUC:0.5881 ACC:0.9194\n",
    "\n",
    "print('Max AUC and Accurancy for Random Forest changing the max_depth param')\n",
    "#calc_max_auc(rf_auc, 1, 50, X_tr_num, X_te_num)\n",
    "# 8 -> AUC:0.6199 ACC:0.9194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "rf_classifier.fit(X_tr_num, y_tr)\n",
    "rf_yscore = rf_classifier.predict_proba(X_te_num)[:,1]\n",
    "print_roc_curve(y_val, rf_yscore, \"Random Forest Depth 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 - categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "cat_cols = ['OCCUPATION_TYPE']\n",
    "X_tr_cat = ohe.fit_transform(train[cat_cols]).toarray()\n",
    "X_tr_all = np.concatenate((X_tr_num, X_tr_cat), axis=1)\n",
    "\n",
    "X_te_cat = ohe.fit_transform(test[cat_cols]).toarray()\n",
    "X_te_all = np.concatenate((X_te_num, X_te_cat), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc_max_auc(rf_auc, 5, 10, X_tr_all, X_te_all)\n",
    "# k:8 -> AUC:0.6231 ACC:0.9176\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "rf_classifier.fit(X_tr_all, y_tr)\n",
    "rf_yscore = rf_classifier.predict_proba(X_te_all)[:,1]\n",
    "print_roc_curve(y_val, rf_yscore, \"Random Forest Depth 8 + categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5 - Compare for example 0.1%, 1%, 10%, 100%.\n",
    "#      Make a plot with the AUC on the y and the fraction of training data on the x.\n",
    "\n",
    "def calc_auc_by_fraction(fraction, train, test, cols):\n",
    "    limit = int(len(train)*fraction)\n",
    "    print(fraction,limit)\n",
    "    tr_fraction = train[:limit]\n",
    "    Xt = tr_fraction[cols]\n",
    "    yt = tr_fraction['TARGET']\n",
    "    Xv = test[cols]\n",
    "    yv = test['TARGET']\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf.fit(Xt, yt)\n",
    "    ysc = clf.predict_proba(Xv)[:,1]\n",
    "    return sklearn.metrics.roc_auc_score(yv, ysc)\n",
    "    \n",
    "#    0.001 - 150 rows\n",
    "aucs = []\n",
    "fractions = np.geomspace(1, 1000, num=4)\n",
    "for f in fractions:\n",
    "    aucs.append(calc_auc_by_fraction(1/f, train, test, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fractions, y=aucs, mode='lines+markers'))\n",
    "fig.update_layout(title=f'AUC decreases using a fraction of training data<br>Training data rows:{len(train)}', xaxis_type='log', xaxis_title='fractions', yaxis_title='AUC', legend=dict(x=-.04, y=-.22))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Download the testing dataset `HomeCredit_test_blind.csv`. It does not contain the target variable. Predict it with your best classifier, and submit the results as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 HomeCredit_test_blind.csv\n",
    "\n",
    "X_te_num = normalize(df_blind, num_cols)\n",
    "X_te_cat = ohe.fit_transform(df_blind[cat_cols]).toarray()  \n",
    "X_te_all = np.concatenate((X_te_num, X_te_cat), axis=1)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(max_depth=8, random_state=0)\n",
    "rf_classifier.fit(X_tr_all, y_tr)\n",
    "rf_yscore = rf_classifier.predict_proba(X_te_all)[:,1]\n",
    "\n",
    "df_te_predictions = pd.DataFrame()\n",
    "df_te_predictions[\"SK_ID_CURR\"] = df_blind[\"SK_ID_CURR\"]\n",
    "df_te_predictions[\"score\"] = rf_yscore\n",
    "\n",
    "your_surname = \"DeSanti\"\n",
    "df_te_predictions.to_csv(f\"HomeCredit_test_scores_{your_surname}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
