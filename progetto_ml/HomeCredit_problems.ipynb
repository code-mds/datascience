{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan repay prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data location: https://drive.switch.ch/index.php/s/pCy5ctcFRsM2RdZ\n",
    "\n",
    "Consider file `HomeCredit_train.csv`, which contains anonymized data shared from a financial institution (https://www.kaggle.com/c/home-credit-default-risk/).\n",
    "\n",
    "Each row is a loan.  See `HomeCredit_description.csv` for a description of the columns (note that we only have a subset of the columns).  The target variable (column `TARGET`) contains 1 if the client had issues repaying the loan, 0 otherwise.\n",
    "\n",
    "If you need it for faster experiments, the file  `HomeCredit_train_small.csv` contains only a small part of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: exploratory analysis\n",
    "Open the dataset using Pandas.\n",
    "\n",
    "### 1.1\n",
    "Which fraction of the loans are not repayed? \n",
    "\n",
    "### 1.2\n",
    "Choose 3 variables you like and whose meaning you understand. Make one or two plots for each to describe its distribution (univariate analysis), and to check whether there is an obvious relation to the target variable (bivariate analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 \n",
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv(\"HomeCredit_train_small.csv\")\n",
    "df = pd.read_csv(\"HomeCredit_train.csv\")\n",
    "df_blind = pd.read_csv(\"HomeCredit_test_blind.csv\")\n",
    "m = df[\"TARGET\"].mean()\n",
    "print(f\"Fraction of not repayed loans = {m:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "df_unpaid = df[df['TARGET']==1]\n",
    "df_paid = df[df['TARGET']==0]\n",
    "\n",
    "def unpaid_comparison(df, df_unpaid, col, title):\n",
    "    ## Counts the occurrence of unqiue elements and stores in a series type\n",
    "    data = df[col].value_counts()\n",
    "    f1 = go.Bar(x=data.values/np.sum(data)*100, y=data.index, orientation='h',\n",
    "                marker_color='rgba(0, 0, 255, 0.7)')\n",
    "\n",
    "    data_unpaid = df_unpaid[col].value_counts() / data * 100.0\n",
    "    data_unpaid.sort_values(ascending=False, inplace=True)\n",
    "    f2 = go.Bar(x=data_unpaid.values, y=data_unpaid.index, orientation='h', \n",
    "                marker_color='rgba(255, 0, 0, 0.7)')\n",
    "    \n",
    "    fig = make_subplots(shared_xaxes=False, rows=2, cols=1, vertical_spacing=0.25)\n",
    "    fig.add_trace(f1, row=1, col=1)\n",
    "    fig.add_trace(f2, row=2, col=1)\n",
    "    fig.update_yaxes(row=1, col=1, autorange=\"reversed\")\n",
    "    fig.update_xaxes(title_text=\"% of people obtained a credit\", row=1, col=1)\n",
    "    fig.update_yaxes(row=2, col=1, autorange=\"reversed\")\n",
    "    fig.update_xaxes(title_text=\"% of not paid loan\", row=2, col=1)\n",
    "    fig.update_layout(title_text=title)\n",
    "    fig.update_traces(showlegend=False)\n",
    "    fig.show()\n",
    "#F    9247/131546\n",
    "#M    6962/68452\n",
    "#XNA  0/2\n",
    "#dfp = df_unpaid['CODE_GENDER'].value_counts() / df['CODE_GENDER'].value_counts() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'CODE_GENDER', 'Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'OCCUPATION_TYPE', 'Occupation Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'NAME_HOUSING_TYPE', 'Housing Situation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'NAME_EDUCATION_TYPE', 'Education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpaid_comparison(df, df_unpaid, 'ORGANIZATION_TYPE', 'Type of organization where client works')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: preparing a training and a validation dataset\n",
    "\n",
    "### 2.1\n",
    "Randomly split the 200k rows of your dataset in two groups; keep 150k rows for training and use 50k for validating your models.\n",
    "\n",
    "### 2.2\n",
    "Choose three variables that are already numeric.  Build the following numpy arrays:\n",
    "- `X_tr` (2 dimensions: 150k rows, 3 columns)\n",
    "- `y_tr` (1 dimension: 150k elements)\n",
    "- `X_val` (2 dimensions: 50k rows, 3 columns)\n",
    "- `y_val` (1 dimension: 50k elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1\n",
    "msk = np.random.rand(len(df)) < 3/4\n",
    "train = df[msk] # 150'000 rows\n",
    "test = df[~msk] # 50'000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2 - numeric variables\n",
    "cols = ['AMT_INCOME_TOTAL','AMT_CREDIT', 'REGION_POPULATION_RELATIVE']\n",
    "\n",
    "X_tr = train[cols]\n",
    "y_tr = train['TARGET']\n",
    "\n",
    "X_val = test[cols]\n",
    "y_val = test['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: training and scoring simple models\n",
    "\n",
    "### 3.1\n",
    "Train a K-Nearest-Neighbors classifier (use the sklearn function) and compute its accuracy on the validation set.  Compare it with the accuracy of a classifier that always returns 0.  Comment.\n",
    "\n",
    "### 3.2\n",
    "Train the classifier with K=20, and use the `predict_proba(...)` function on the trained classifier to obtain a *score* for each instance in the validation set.  Consider the distribution of the scores returned for the instances of the validation set.\n",
    "\n",
    "Describe what is in this context the concept of TP, TN, FP, FN, TPR, FPR.\n",
    "\n",
    "Write a function that given a threshold, computes the number of TP, TN, FP, FN. \n",
    "\n",
    "How would you describe what the TPR and FPR are in this context?\n",
    "\n",
    "\n",
    "### 3.3\n",
    "Using your function defined above, compute the TPR and FPR for a large number of different thresholds.  Plot the ROC curve.\n",
    "\n",
    "Using the [appropriate sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html), compute the AUC of your classifier.\n",
    "\n",
    "### 3.4\n",
    "Draw the ROC curve and compute the AUC value for two \"dummy\" classifiers:\n",
    "- one that always returns a score of 0 for each sample\n",
    "- one that returns a random score for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=2)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "y_hat = clf.predict(X_val)\n",
    "accurancy_kn = np.mean(y_hat == y_val)\n",
    "print(f'Accurancy KN(2) {accurancy_kn}')\n",
    "\n",
    "y_hat_dummy = [0] * len(y_val)\n",
    "accurancy_dummy = np.mean(y_hat_dummy == y_val)\n",
    "print(f'Accurancy Dummy {accurancy_dummy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 - Train the classifier with KNeighborsClassifier using n_neighbors=20\n",
    "\n",
    "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=20)\n",
    "clf.fit(X_tr, y_tr)\n",
    "y_score = clf.predict_proba(X_val)[:,1]\n",
    "y_hat = y_score > 0.5\n",
    "np.mean(y_hat == y_val)\n",
    "\n",
    "def roc_calculator(t, y_val, y_sc):\n",
    "    matrix = sklearn.metrics.confusion_matrix(y_val, y_sc > t)\n",
    "    TN=matrix[0][0]\n",
    "    FP=matrix[0][1]\n",
    "    FN=matrix[1][0]\n",
    "    TP=matrix[1][1]\n",
    "    # FNR = False Negative Rate \n",
    "    FNR=FN/(FN+TP)    \n",
    "    # FPR = False Positive Rate \n",
    "    FPR=FP/(TN+FP)\n",
    "    # TPR = True Positive Rate\n",
    "    TPR=1-FNR \n",
    "    return TPR, FPR\n",
    "\n",
    "# Descrizione nel contesto del problema\n",
    "# [TN, FP] -> TN+FP = Totale Paganti\n",
    "# [FN, TP] -> FN+TP = Totale Insolventi\n",
    "# TP = Abbiamo correttamente predtto come non-paganti.\n",
    "# TN = Abbiamo correttamente predtto come paganti.\n",
    "# FP = Abbiamo erroneamente predtto come non-paganti.\n",
    "# FN = Abbiamo erroneamente predtto come paganti.\n",
    "# TPR = La percentuale delle predizioni corrette di non paganti.\n",
    "# FPR = La percentuale delle predizioni incorrette di non paganti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.3\n",
    "def print_roc_curve(y_val, y_sc, name):\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    AUC = sklearn.metrics.roc_auc_score(y_val, y_sc)\n",
    "    \n",
    "    for i in  np.arange(0, 1, 0.02):\n",
    "        TPR,FPR = roc_calculator(i, y_val, y_sc)\n",
    "        x_values.append(FPR)\n",
    "        y_values.append(TPR)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=x_values, y=y_values, mode='lines+markers', name=name))\n",
    "    fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='baseline', line=dict(width=2, dash='dash')))\n",
    "    fig.update_layout(title=f'{name} ROC curve. AUC={AUC:.2f}', xaxis_title='%FP', yaxis_title='%TP', legend=dict(x=-.04, y=-.22))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_roc_curve(y_val, y_score, 'kneighbour 20 classifier')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.4\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_classifier = DummyClassifier(strategy=\"uniform\")\n",
    "random_classifier.fit(X_tr, y_tr)\n",
    "y_score_random = random_classifier.predict_proba(X_val)[:,1]\n",
    "print_roc_curve(y_val, y_score_random, \"random classifier\")\n",
    "\n",
    "zero_classifier = DummyClassifier(strategy=\"constant\", constant=0)\n",
    "zero_classifier.fit(X_tr, y_tr)\n",
    "y_score_zero = zero_classifier.predict_proba(X_val)[:,1]\n",
    "print_roc_curve(y_val, y_score_zero, \"zero classifier \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: training better models (optional)\n",
    "\n",
    "### 4.1\n",
    "Normalize the data and repeat the analysis. Is the accuracy better?\n",
    "\n",
    "### 4.2\n",
    "Try using other classifiers.  A good option is the [random forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "### 4.3\n",
    "Try using more numerical features.\n",
    "\n",
    "### 4.4\n",
    "There is a lot of information also in the categorical features. Find a way to use them in a classifier.  For example, you can use One Hot Encoding, implementing it manually or by using the [appropriate sklearn function](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).\n",
    "\n",
    "### 4.5\n",
    "Given a classifier, study how the AUC on the validation data decreases if you use only part of the training data.  Make a plot with the AUC on the y and the fraction of training data on the x. Compare for example 0.1%, 1%, 10%, 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1\n",
    "\n",
    "#TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2\n",
    "randomforest_classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "randomforest_classifier.fit(X_tr, y_tr)\n",
    "y_score_randomforest = randomforest_classifier.predict_proba(X_val)[:,1]\n",
    "print_roc_curve(y_val, y_score_randomforest, \"random forest classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 - Try using more numerical features.\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 - categorical features\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc_df = pd.DataFrame(enc.fit_transform(df[['CODE_GENDER']]).toarray())\n",
    "df_cat = df.join(enc_df)\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.5 - Compare for example 0.1%, 1%, 10%, 100%.\n",
    "#      Make a plot with the AUC on the y and the fraction of training data on the x.\n",
    "\n",
    "def calc_auc_by_fraction(fraction, train, cols):\n",
    "    limit = int(len(train)*fraction)\n",
    "    print(fraction,limit)\n",
    "    tr_fraction = train[:limit]\n",
    "    Xt = train[cols]\n",
    "    yt = train['TARGET']\n",
    "    Xv = test[cols]\n",
    "    yv = test['TARGET']\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf.fit(Xt, yt)\n",
    "    ysc = clf.predict_proba(Xv)[:,1]\n",
    "    return sklearn.metrics.roc_auc_score(yv, ysc)\n",
    "    \n",
    "#    0.001# 150 rows\n",
    "aucs = []\n",
    "fractions = np.geomspace(1, 1000, num=4)\n",
    "for f in fractions:\n",
    "    aucs.append(calc_auc_by_fraction(1/f, train, cols))\n",
    "    \n",
    "aucs\n",
    "\n",
    "\n",
    "# import sklearn.linear_model\n",
    "# import ipywidgets as iw\n",
    "# import sklearn.metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Download the testing dataset `HomeCredit_test_blind.csv`. It does not contain the target variable. Predict it with your best classifier, and submit the results as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
